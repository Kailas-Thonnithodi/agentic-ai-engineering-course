{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301f421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "import random \n",
    "import gradio as gr\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e140213",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\", \"Zombies\", \"Rainbows\", \"Eels\", \"Pickles\", \"Muffins\"]\n",
    "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\", \"sparkly\", \"untrustworthy\", \"saracastic\", \"squishy\", \"haunted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024ea21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025e500",
   "metadata": {},
   "source": [
    "Annotated gives a better description for type hinting (for other developers and better annotations especially for langgraph)\n",
    "\n",
    "Langgraph needs to use this feature when we define state objects. This is due to telling it what funciton it should call to update the State with a new value (a reducer). The default reducer is add_messages (from the langgraph.graph.message library)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34876fa3",
   "metadata": {},
   "source": [
    "1. Define the State Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dae2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517eb9ef",
   "metadata": {},
   "source": [
    "2. Start the Graph Builder (with initialise state class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6ef1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d94f58",
   "metadata": {},
   "source": [
    "3. Create a Node\n",
    "\n",
    "Nodes (any python function). In this case the reducer that we set before gets automatically called to combine this response with previous responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce7edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_node(previous_state: State) -> State:\n",
    "    # node will respond with a response describling a noun. \n",
    "    reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}\" \n",
    "    messages = [{\"role\": \"assistant\", \"content\": reply}]\n",
    "    new_state = State(messages=messages)\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1320cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1110aebd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"first_node\", first_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553d25d",
   "metadata": {},
   "source": [
    "4. Create Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9ff7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1110aebd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# START --> first_node --> END\n",
    "graph_builder.add_edge(START, \"first_node\")\n",
    "graph_builder.add_edge(\"first_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b234621",
   "metadata": {},
   "source": [
    "5. Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3423656",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18847ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\nconfig:\\n  flowchart:\\n    curve: linear\\n---\\ngraph TD;\\n\\t__start__([<p>__start__</p>]):::first\\n\\tfirst_node(first_node)\\n\\t__end__([<p>__end__</p>]):::last\\n\\t__start__ --> first_node;\\n\\tfirst_node --> __end__;\\n\\tclassDef default fill:#f2f0ff,line-height:1.2\\n\\tclassDef first fill-opacity:0\\n\\tclassDef last fill:#bfb6fc\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for visualisation purposes\n",
    "display(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58341ff",
   "metadata": {},
   "source": [
    "Gradio Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5036f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(result)   \n",
    "    return result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b78b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='910a3752-5a85-4aff-ad39-171e96c18383'), AIMessage(content='Muffins are sparkly', additional_kwargs={}, response_metadata={}, id='52a996fd-4203-4526-90ce-39a61c7b3cdb')]}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type='messages').launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
