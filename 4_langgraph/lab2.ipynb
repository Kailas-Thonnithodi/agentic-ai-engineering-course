{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5408cd09",
   "metadata": {},
   "source": [
    "## The Super Step\n",
    "* A single iteration over the graph nodes. \n",
    "* Nodes that run in parallel are part of the same super-step, while nodes that run sequentially belong to separate super-steps. \n",
    "* The graph describles one super-step; one interaction between agents and tools to achieve an outcome. This means every user interactino is a fresh graph.invoke(state) call. \n",
    "* The reducer handles updating state during a super-step but not between super-steps. \n",
    "\n",
    "For examples\n",
    "1. DEFINE GRAPH (the 5 step process of initalising a graph)\n",
    "2. Super-step (user asks the chatbot about a question)\n",
    "3. Super-step (user asks a follow up question)\n",
    "4. ...\n",
    "\n",
    "This is important as we need to keep checkpoints of each iteration (each iteration of a super-step) to diagonise how the model is thinking for each each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5a4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.agents import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "import sqlite3\n",
    "from typing import Annotated, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1af274",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "serper = GoogleSerperAPIWrapper()\n",
    "serper.run(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb11137",
   "metadata": {},
   "source": [
    "functions --> tool conversion (using langchain)\n",
    "Tool has the following params\n",
    "* name of the tool\n",
    "* function which should be executed\n",
    "* description of the function which is being executed.\n",
    "\n",
    "In Lang graph the tools need to be used respectively\n",
    "* Changes to provide the tools to OpenAI in json when we make the call\n",
    "* Changes to handle the results back: look for the model staying that the finish_reason=\"tool_calls\" and then retrieve the call, run the function, provide the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_search = Tool(\n",
    "    name=\"search\",\n",
    "    func=serper.run,\n",
    "    description=\"Useful for hwen you need more information form an online search.\"\n",
    ")\n",
    "\n",
    "# tool_search.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88688ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5519a3b2",
   "metadata": {},
   "source": [
    "# Initalise LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e6e07",
   "metadata": {},
   "source": [
    "initalise first state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2760cf",
   "metadata": {},
   "source": [
    "Initalise graph with first state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d414666",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# instead of creating a json for each tool, langchain packages by initalising it in another llm (easily retrieveable)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f66bf4",
   "metadata": {},
   "source": [
    "create a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    # packaging the tool into json version\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "# actual calling of the tool function (special node)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf8bd0",
   "metadata": {},
   "source": [
    "creating edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95760a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional edge which calls tools based on an \"if\"\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition, \"tools\")\n",
    "\n",
    "# ontop of the creating the conditional edge, you need to still establish the edge connection with tools and chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2f80a",
   "metadata": {},
   "source": [
    "compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09022c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e2f9c",
   "metadata": {},
   "source": [
    "Broken lines means, if the chatbot calls tools node, then execute the tools node and return back to the chatbot inital state of mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583f486",
   "metadata": {},
   "source": [
    "Run the following model in gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]})\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "# gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124f039",
   "metadata": {},
   "source": [
    "Currently the model doesn't have retention for memory. This is due to a super step being considered as a single iteration over the graph nodes. Nodes that run in parallel are port of the same super-step, whilst nodes that run sequentially belong to separate super-steps.\n",
    "\n",
    "In shorter terms 1 super step of the graph represents one invocation of passing message between the agent. You call invoke to run your graph for each super-step (for each interaction). The reducer handles state updates automatically within one super-step, but not between them. This is what checkpointing achieves (keeps with memory retention)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b63fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Step 1\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 and 2\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Step 3\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    print(state)\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "# Step 4\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition, \"tools\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Step 5\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90017c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}} # attachment to the first thread in memory.\n",
    "\n",
    "def chat(user_input: str, history):\n",
    "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
    "    return result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57be6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e645867",
   "metadata": {},
   "source": [
    "The following is function which will show the history behind each super step. basically every time the graph is invoked (every interaction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef81ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41940657",
   "metadata": {},
   "source": [
    "Furthermore, LangChain gives you tools to set the state back to a prior point in time, to branch off (based on a checkpoint id (from the history))\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\"}}\n",
    "\n",
    "graph.invoke(None, config=config)\n",
    "\n",
    "Furthermore, This would allow you to build a stable system that can be recovered (time travelled back similar to how you can edit a response in gpt) and re-run from a specified prior checkpoint in the config memory space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11479b",
   "metadata": {},
   "source": [
    "Also another to note, you can run this in parallel with another chatbot, by using a different memorysaver instances and creating repeating the steps again for the creating the langgraph structure.\n",
    "\n",
    "EVEN BETTER YOU CAN CHANGE THE THREAD ID in the memory saver instance to talk another model with different instances of data retention. I Would assume that you can store these the retention values based on their thread id or thread number into an sql database (along with the chat history and super step history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of memory saver we are using sqlite3 for saving memory\n",
    "database_path = \"/Users/goldenmeta/Github/uDemy/SQLite3/langgraph_sample.db\"\n",
    "connection = sqlite3.connect(database_path, check_same_thread=False)\n",
    "sql_memory = SqliteSaver(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_search = Tool(\n",
    "    name=\"search\",\n",
    "    func=serper.run,\n",
    "    description=\"Useful for when you need more information from an online search.\"\n",
    ")\n",
    "\n",
    "tools = [tool_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 (Initial State)\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d06398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 (Create Inital Graph with Starting State)\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d5f2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 3 (Initialise the model and tools, and their respective nodes).\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mChatOpenAI\u001b[49m(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m model_tools = model.bind_tools(tools)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchatbot\u001b[39m(state: State):\n",
      "\u001b[31mNameError\u001b[39m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 3 (Initialise the model and tools, and their respective nodes).\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "model_tools = model.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    print(state)\n",
    "    return {\"messages\": [model_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
